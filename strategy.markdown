---
title: Strategy
layout: default
---
<meta name="robots" content="no index">



# Strategy

This document outlines iMarc’s strategy process and deliverables. This incorporates practices from UX, IA, needs analysis, and business development.

iMarc is a full service web agency located north of Boston. Learn more at [http://imarc.net](http://imarc.net).



## Goals

The goal of all strategy activity is to produce a clear and concise blueprint for an application or website. **Strategy work should clearly define the project for the client and production team while focusing on a positive end-user experience.**

Strategy work will sanity check recommendations from the proposal against actual client needs. Strategy deliverables override recommendations from the proposal where necessary and agreed upon by the client.

When proposals specify time or cost budget for production, strategy deliverables must define a project that can be easily produced within those limitations.



## Key Terms


Deliverable
: A document or similar *work product* you can give to someone.

Task
: An activity you *do*. It is *not* a deliverable.

Time Reqs
: The number of hours required to produce an activity or deliverable, for an *average-sized project*.

Scope
: The *total hours* allocated to the project, and mandatory *features*. Scope is defined by a [Proposal](#Proposal) or a [Statement of Work](#StatementofWork), and should be restated in the Requirements.

Requirements
: What the end product must do. Defined by a [Functional Requirements](#FunctionalRequirements) or a [Production Specification](#ProductionSpecification) document.

Implementation
: How the end product must work. Defined by a [Production Specification](#ProductionSpecification).


## Process

The strategy process is provided to clients who have engaged iMarc by approving a proposal which includes a specified time and cost budget for strategy. Smaller projects that do not explicitly define a strategy budget or scope should bypass the strategy team and go directly to a production team.

The overall process typically looks something like this:

1. Define project objectives
1. Conduct discovery and report findings
1. Define content and tools via spec doc(s)

Strategy begins with an internal handoff meeting between the proposal author and strategy team.

Before strategy work begins, the proposal author is responsible for notifying the client that project leadership is changing hands and the lead strategist is now their primary point of contact.


### Team Members and Roles

During large-scale strategy engagements, the ideal strategy team will consist of:

Producer
:	Sets high-level milestones;  
	Consulted on spec and strategy deliverables;  
	Approves spec doc before production

Strategist
:	Leads the strategy phase;  
	Manages most client meetings;  
	Responsible for presenting deliverables and adhering to timeline;  
	Sets day-to-day tasks and due dates for team;  
	Delegates tasks to other team members;  
	Delivers change orders when the scope of the strategy phase, or the production work that strategy is defining, changes

UX Engineer
:	Conducts [discovery activities](#DiscoveryActivities) and produces deliverables and supporting documents, delegated by the Strategist

Designer
:	May participate in discovery and interviews;  
	Is consulted on wireframes

Engineer
:	Handles engineering tasks and/or research, delegated by the Strategist

The Designer, Engineer and UX Engineer(s) will stick with the project after the strategy phase is complete. This ensures that the Engineer and Designer are familiar with the plan and are prepared to execute. The UX Engineer provides consistency, shepherding the vision architected during the strategy phase and forged in production.




### Approvals

The output of strategy are concrete reference documents. Deliverables are approved both by the client and by the iMarc project producer.

If the client also engages iMarc to produce the project, the strategy lead is responsible for notifying the client that project leadership is changing hands. The Producer is the primary point of contact during the production phase. The Strategist typically withdraws to an advisory-only role (i.e., answering questions about spec or scope, reviewing initial creative work, and helping with QA after development).




## Discovery Activities

Depending on budget and goals, a number of research activities may be incorporated into a project. 

Most are qualitative, meaning they depend heavily upon the expertise and experience of the researchers—for example, interviews and hallway testing. Some are quantitative, meaning they are designed to produce a measurable result—for example, surveys and analytics. Designing meaningful quantitative research takes time, budget and substantial expertise; few projects actually require this, but the ones that do will benefit greatly.



### Goal Analysis and Prioritization

Objective
:	Review and prioritize goals based on business requirements and audience needs.

Tasks
:	Explore and prioritize the client's business environment, target audiences, goals and key challenges.

Deliverables
:	Findings are summarized in the [Discovery Report](#DiscoveryReport).

Time Req
:	22-28 hours

**Topics include:**

+ Business overview, including services, customers and market situation
+ Prioritized goals
+ Known challenges
+ Target audiences


### User Interviews

Objective
:	Find out not just what users are doing, but *why*. The better we understand the users' motivations, the better we can fulfill their needs.

Tasks
:	Locate, contact and talk to the *actual users* of the site or application, conducting contextual, unbiased interviews.

Deliverables
:	The results are summarized for the client in the [Discovery Report](#DiscoveryReport). Occasionally, a dedicated findings report is created for this component.

Time Req
:	30 hours for 6 users interviews and inclusion in Discovery Report

User interviews can take place in person or remotely over the phone, with or without screen sharing. We create a script and a list of questions to ensure consistency.

Interviews can explore concrete items, such as user interface components, design elements, document flow, feature importance, technical knowledge, and devices used (pc, tablet, phone…).  But to be most effective, interviews should explore more fundamental issues.

**Topics include:**

+ What do users want? What are they really trying to do?
+ What frustrates them?
+ What makes them happy? 
+ Is the task we're fulfilling their primary goal, or is it part of something else? 
+ Are there other tools or competitors they might consider? 
+ What is the environment where they use the system? 
+ If they're mobile, are they walking around a noisy factory floor, or driving from office to office? 
+ If they're not mobile, do they use a desktop PC, a laptop with a big screen, laptop with tiny screen?

Some organizations will have people who are in daily contact with users, and have valuable insight into what makes users "tick". Customer service and technical support teams are often treasure troves of insight, with "on the ground" knowledge dwarfing that of sales and marketing personnel. Their experience is invaluable, especially for consumer-facing organizations, or if for any reason we can't talk to the actual end users.


### Stakeholder Interviews

Objective
:	Identify and gain consensus among the client's decision makers.

Tasks
:	Speak with key stakeholders. Understand and document their pain, aspirations, and goals for the project.  

Deliverables
:	The results are summarized for the client in the [Discovery Report](#DiscoveryReport). Occasionally, a dedicated findings report is created for this component.

Time Req
:	32–68 hours for 6–12 stakeholders and inclusion in Discovery Report


Stakeholder interviews help uncover the desires and goals of each decision maker involved in the project. Often, the needs of different stakeholders must be balanced or prioritized; the interviews help make informed recommendations.

Even if the client's senior stakeholders aren't in every meeting, the client team and strategy team should be aware of all people with decision making or veto authority.

**Topics include:**

+ What are the success metrics?
+ Who are the audience segments?
+ What do their customers or users need?
+ Is there any market research?
+ What will make them successful?
+ What challenges do they face?

Stakeholder interviews often turn up new information, issues and objectives.

Stakeholders often mistake their own needs for their users' needs. It's our job to help align stakeholder's goals with our users' needs.

Batching in small groups can reduce time spent on-site but saves little time overall, and tend to result in less detailed information from all participants. Interviewing senior stakeholders effectively tends to be staff- and time-intensive.


### Competitive Analysis

Objective
:	Give clients a view of how their competitors fare on the web.

Tasks
:	Look for patterns and best practices in content, layout, navigation, workflow, and SEO.

Deliverables
:	A competitive analysis should culminate in specific recommendations for the project, as part of the [Discovery Report](#DiscoveryReport). Occasionally, a dedicated findings report is created for this component.

Time Req
: 16–32 hours, depending on breadth and depth


Typically we look for patterns and best practices among:

+ **Content:**  Who is it written for, and why? How do they persuade visitor? What is the style?
+ **Layout:** What is typical of page density, visual impact, and calls to action?
+ **Navigation structure:** What forms of navigation are used? (main, breadcrumbs, footer, etc). Is it consistent? What kind of language is used? Is it discoverable?
+ **Workflows:** If the user can conduct tasks (shopping, service sign-up, share content, etc), how does it work and how does it further the user's goals? Is it easy? Is it delightful?
+ **SEO audit:** What pages are indexed? What meta and title info are used? Is there a sitemap.xml or robots.txt, and if so, what do they indicate?

*Caution:* Just because something commonly is done a certain way does not mean it is the *best way*. You should use your own judgement; the goal of a competitive analysis is not to comply with the lowest common denominator, but to find the very best practices.


### Web Analytics Audit

Objective
:	Help clients understand where their site has performed well or poorly.

Tasks
:	Explore trends and patterns in user activity, content, and page flows.

Deliverables
: 2–4 page summary of most important analytics data findings.

Time Req
:	6–8 hours and inclusion in Discovery Report

The primary purpose of this document is to identify and convey past patterns in user activity, page flows, and content to better inform decisions during planning, design and development. It is necessarily backwards-looking.


### Metrics Baseline

Objective
:	Help clients measure the effectiveness of their site.

Tasks
:	Talk to core stakeholders, identify metrics for success based on their business activities, and document and prepare those metrics for implementation by the development team.

Deliverables
: 1–2 page stand-alone report or inclusion in Discovery Report. The findings and metrics should be incorporated into the site Requirements or Specification.

Time Req
:	6–8 hours

The Metrics Baseline is a forward-looking activity that builds upon the Web Analytics Audit findings to establish what metrics will be used to measure conversion and site performance *after* launch. 

It should provide metrics both for general performance and specific indicators:

+ **General Performance**  
5–10 trackable, standard metrics for the site overall which will help the client understand where their site is performing well, or needs improvement. For example, natural search referrals, length of visit, depth of visit, bounce rate, etc.

+ **Specific Indicators**  
5 KPIs or event triggers that can be used to measure *conversions* (e.g., ”Request a Quote“ form submissions, course sign-up.); *value* (e.g., average order total…); or *behaviors* (e.g., Visitor loyalty and recency, days & visits to purchase, checkout abandonment rate, task completion rate…).

In both cases, set a baseline to measure improvement (if possible). If the client is active in social media, also measure [amplification and applause](http://www.kaushik.net/avinash/best-social-media-metrics-conversation-amplification-applause-economic-value/) rates.



### Surveys

Objective
:	Gather information from a large number of participants, yielding results in quantitative terms. 

Tasks
:	Design a set of closed-ended questions, distribute the survey to users (see [survey tools](#SurveysandTesting) below), analyze the results.

Deliverables
:	Results are delivered as part of the [Discovery Report](#DiscoveryReport).

Time Req
: 32–40 hours per survey and inclusion in the discovery report. If also recruiting, add 8-12 hours.


Questions should be close-ended fashion (multiple choice, Yes/No, True/False). This makes it easy for participants to respond, and easier for us to analyze. For example, *We found that 83% of participants prefer to book their ferry ride online between 11am and 2pm on weekdays.*

*Caution:* Surveys can only answer the questions we know to ask; unlike interviews and usability testing, they rarely produce novel findings.

Watch out for [confirmation bias](http://en.wikipedia.org/wiki/Confirmation_bias) creeping into survey design and interpretation.



## Deliverables and Supporting Documents

During the strategy process, we'll refer to and create a number of deliverables. Not all deliverables are needed for every project. The commonest are described here.


### Proposal

A proposal is created by Business Development and is a sales tool. It defines the project scope, suggests features and functionality, and usually includes quite a lot of background research and client goals. *Every strategy participant should read the proposal, in its entirety.*


### Statement of Work

A Statement of Work, or SOW, may be created by Business Development or a Producer. It's not a sales tool. SOWs are used for existing clients who don't need to be sold on iMarc as a vendor. An SOW defines project scope, features and functionality. It usually does not include background research & discovery, and rarely requires a [Technical Specification](#TechnicalSpecification) before production.


### Discovery Report

Summary
:	A 10–25 page document summarizing the results of all [Discovery Activities](#DiscoveryActivities) and providing specific recommendations for the project, for projects with production scope *over 200 hours*.

Time Req
:	Sum of Discovery Activities conducted (above)


The Discovery Report documents what we've learned, and provides specific recommendations for use in developing the [site map](#SiteMap), [wireframes](#Wireframe), and [specification](#ProductionSpecification).

Its secondary goal is to ensure internal stakeholders agree upon the project's objectives and priorities before creating a Production Specification.

**Topics include:**

+ [Goal Analysis and Prioritization](#GoalAnalysisandPrioritization)
+ [Web Analytics Audit](#WebAnalyticsAudit)
+ [Metrics Baseline](#MetricsBaseline)
+ [Competitive analysis](#CompetitiveAnalysis)
+ [Stakeholder interview](#StakeholderInterviews) findings (if conducted)
+ [User interview](#UserInterviews) findings (if conducted)
+ [Survey](#Surveys) findings (if conducted)
+ [Usability Testing](#UsabilityTesting) results (if conducted)
+ Recommendations

The Discovery Report serves as a foundation for the next documents: site map, wireframes, and specifications.



### Site Map

Summary
:	Diagram showing the relationship of a web site's information and organization of content. 

Time Req
: N/A (Not usually broken out from [Functional Requirements](#FunctionalRequirements) or [Production Specification](#ProductionSpecification))

+ Convey content hierarchy and labeling
+ Denote CMS-controlled content and template usage
+ Create a navigational backbone for a website

#### Example Sitemap:
![Sample Site map](img/strategy/sitemap.png)


### Content Outline

Summary
:	Briefly describes the purpose and goal of each page on the site.

Time Req
: N/A (Not usually broken out from [Functional Requirements](#FunctionalRequirements))


The content outline supplements a Site Map. A content mimics the the organization of the site map, providing 1-2 sentences about the purpose and goal of each page. Typically a component of the Functional Requirements.

#### Example Content Outline
![Sample Content Outline](img/strategy/content_outline.png)


### Homepage Narrative

Summary
: Brief, 1-2 page document that defines all content, features and functionality required for the homepage. 

Time Req
:	4–6 hours, and inclusion in the Functional Requirements Document

This simple list and description acts as a starting point for the design and creative phase. It is done instead of a wireframe.


### Wireframe

Summary
: User interface and content illustration stripped of all presentational style. 

Time Req
: 8–12 hours per page or screen


A wireframe is a bit of a "sneak preview" of the site for our clients, and helps them visualize the ideas being discussed and get buy-in from stakeholders.

Most wireframes will depict single web pages, but some may depict multiple screens in a complex interaction or workflow.

*Multi-screen* explorations are called *storyboards*. The time required is cumulative: a four-screen storyboard will take 32-48 hours of work to create, revise and approve.

+ Allows for rapid, efficient UI iteration
+ Conveys what a page or screen does
+ We often create multiple wireframes express various parts of the site
+ Annotated to describe behaviors, functionality, and content needs.
+ Should not depict creative design. However, design is inextricably linked to layout, so you should consult a UX Engineer or Designer on wireframes. Often, they will be the principal authors.

#### Example Wireframe:
![Example of Wireframe](img/strategy/wireframe.png)




### Functional Requirements

Summary
:	A 5-10 page document for projects with production scope *under 200 hours*.

Time Req
:	32 hours, *in addition to Discovery Activities*.


This document should restate scope of production phase (which often changes somewhat during discovery), and must be approved by the client. It describes business needs driving the project, and describes front-end functionality (what, not how). It typically includes a [Site Map](#SiteMap) and [Homepage Narrative](#HomepageNarrative). It should be reviewed by the Producer before finalization, and may include or reference change orders vs the proposal scope.



### Production Specification

Summary
:	A 15–80 page document for projects with production scope *over 200 hours*.

Time Req
:	 90–170 hours, *in addition to Discovery Activities*.


Like a Functional Requirements document, it's created by a Strategy team in close collaboration with the client. It restates the scope of production and must be approved by the client. It includes everything in Functional Requirements, *plus*:

+ Describes back-end functionality such as CMS tools, fields and relationships; databases; network and server infrastructure; external systems the site works with; security considerations.
+ Must be reviewed by the Producer and an engineer before finalization.
+ May also be reviewed on an ad hoc basis by UX, Creative, BizDev or others identified by the Producer or Strategist.

(This is somewhat akin to a [Functional Specification](http://en.wikipedia.org/wiki/Functional_specification). However, it's not as detailed: we are not building the Space Shuttle, and there is room for improvisation. Our developers have tremendous domain knowledge; it's important to let them exercise it. See also Joel Spolsky's [Painless Functional Specifications](http://www.joelonsoftware.com/articles/fog0000000036.html) series.)




## Usability Testing

The best way to find out what does or does not work well is by asking *real people* to try it. 

Usability testing can be used to improve existing systems, or while developing new ones. We engage in several types of testing.


### Hallway Testing

Objective
:	Answer simple usability questions quickly and cheaply.

Tasks
: Recruit a passer-by and ask them to do a specific task.

Deliverables
:	N/A; conducted during design or development as needed.

Time Req
:	0\.5 hours per task per person

[Hallway testing](http://en.wikipedia.org/wiki/Usability_testing#Hallway_testing) is informal, easy, cheap, fast, and not very rigorous. It answers simple questions quickly.

See also [Hallway usability testing: How much of the UI do you actually make functional?](http://stackoverflow.com/questions/1864212/hallway-usability-testing-how-much-of-the-ui-do-you-actually-make-functional) at Stack Overflow.


### Heuristic Evaluation

Objective
:	Create oral or written suggestions for improvements in a design or system.

Tasks
: Evaluate a user interface against usability principles and provide recommendations for improvement.

Deliverables
:	Results may be delivered as part of the [Discovery Report](#DiscoveryReport) or as a dedicated findings report.

Time Req
:	6–8 hours and inclusion in the Discovery Report

Experienced usability team members evaluate the user interface (current or planned), judging compliance with recognized usability principles, and provide oral or written suggestions for improvements. This is informal and relatively quick, but depends upon an experienced evaluator. It is well-suited to aggressive project schedules.

A good starting point for this is Jakob Nielsen's [10 Heuristics for User Interface Design](http://www.nngroup.com/articles/ten-usability-heuristics/) and [How to Conduct a Heuristic Evaluation](http://www.nngroup.com/articles/how-to-conduct-a-heuristic-evaluation/) articles; Abby Covert's [Information Architecture Heuristics](http://www.slideshare.net/AbbyCovert/information-architecture-heuristics) is great too.


### Structured Usability Testing

Objective
:	Make a site or application easier to use and more effective at its purpose.

Tasks
: Create a list of tasks to test; create a prototype; put humans in front of it; give them the tasks; record what happens.

Deliverables
:	Results may be delivered as part of the [Discovery Report](#DiscoveryReport) or as a dedicated usability findings report.

Time Req
:	64–80 hours per round, with 4-5 users, and written usability report and recommendations. 

Usability testing involves putting actual people in front of a real or mocked up site, giving them tasks, and seeing what happens. This tends to produce the most new insights of any form of testing.

It's best to start with a list of questions that need answering, such as *can users easily sign up for a workshop?* or *does breaking the checkout into three steps make it easier to use than the current site?*

Next, create a formal task list and script, recruit [4 to 5 users](http://www.nngroup.com/articles/why-you-only-need-to-test-with-5-users/) ([rarely more](http://www.nngroup.com/articles/how-many-test-users/)), and one at a time sit with each of them in front of a computer and ask them to perform specific tasks. One person runs the test, being as careful as possible not to lead the tester; other team members may observe by screen-share and one-way audio.

The script helps to ensure consistency, video recording the screen lets us revisit the tests. 

Steve Krug's book [Rocket Surgery Made Easy]() is an excellent guide to designing and conducting usability testing. Another useful (and shorter) work is Jacob Nielsen's [Travelling Usability Lab](http://www.nngroup.com/articles/traveling-usability-lab/) article.



## Quality Assurance

Objective
:	Ensure the site or application meets the requirements laid out in the [Functional Requirements](#FunctionalRequirements) or [Production Specification](#ProductionSpecification) document. Find bugs.

Tasks
: Test every function described in the requirements or spec against expected behavior, and make sure the required content is present and correct.

Deliverables
:	Issues should be entered as tickets in iMarc's [Workshop](https://workshop.imarc.net). The Producer will traffic them.

Time Req
:	N/A (not budgeted with strategy)

After design and development, before launch, iMarc employees who were not involved in creating the site assess the site for compliance with the project requirements, for general bugs, and for usability issues. 

QA serves as a "last pass" to catch anything missed during production.



## Tools

The most important qualification for a tool is *fitness for purpose*. We constantly evaluate alternatives; if you think a tool shows promise, try it out; if it works well, add it to Handbook.

### Wireframes and Sitemaps

[OmniGraffle Pro](http://www.omnigroup.com/products/omnigraffle) is used for site maps and wireframes. In the past, we've also had good results from [Mockingbird](https://gomockingbird.com) and [Balsamiq](http://www.balsamiq.com).

We generally use the [Konigi stencil set](http://konigi.com/tools/omnigraffle-wireframe-stencils) for wireframes. This provides a remarkably complete set of user interface components for web sites, applications and mobile devices.

We also have created an "iMarc Objects" OmniGraffle stencil with some commonly used elements, including iMarc-branded metadata blocks.


### Reports and Specs

We use [Word](http://www.microsoft.com/mac/word) for most reports and specs, but are not married to it. We prefer Word's .docx file format for its superior change tracking capabilities. Branded templates can be downloaded from [our intranet](http://internal.imarc.net/).

We've used [Pages](http://www.apple.com/iwork/pages/), however the revision tools and cross-platform compatibility might cause collaboration issues. We sometimes use [Google Docs](http://docs.google.com) through iMarc's Google Apps account. Google Docs should not be created or edited using personal accounts.

We use [Keynote](http://www.apple.com/iwork/keynote/) when presenting on-screen. Branded templates can be downloaded from [our intranet](http://internal.imarc.net/).


### Surveys and Testing

[Survey Monkey](http://surveymonkey.com) is used to conduct user surveys.

[Treejack](http://www.optimalworkshop.com/treejack.htm) is used for testing content structure and navigation.

[Camtasia](http://www.techsmith.com/camtasia.html) is used for conducting in-person user testing. Camtasia records the session screen and audio.

[GoToMeeting](http://www.gotomeeting.com/fec/) is used for remote user testing.



### Document Metadata

Strategy deliverables should contain some combination of the following meta information.

Client
: Example: *iMarc LLC*

Project
: Example: *Website Redesign*

Document Title
: Example: *Product Detail Page Wireframe*

Version
:	A number used as collaboration aid to identify a specific document. If changes are made to a published or shared document, the version number should increase.  
Example: *v7*

Last Updated
:	Full date that the document was last updated  
Example: *September 4, 2012*

Author
:	Each document has one author. The last person to touch the document is the author of record and is responsible for its contents.  
Example: *David Tufts*

Revision Notes
:	What changed in this revision; mainly used in Functional Requirements and Production Specification documents.

#### Example of document metadata:

![Wireframe title, date, annotations](img/strategy/metadata-wireframe.png)


 